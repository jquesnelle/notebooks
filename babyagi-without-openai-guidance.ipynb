{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to Guidance: BabyAGI without OpenAI\n",
    "\n",
    "* _Twitter: [theemozilla](https://twitter.com/theemozilla)_\n",
    "* _Jupyter Notebook: [babyagi-without-openai-guidance.ipynb](https://github.com/jquesnelle/notebooks/blob/master/babyagi-without-openai-guidance.ipynb)_\n",
    "\n",
    "### Guidance\n",
    "\n",
    "_If you're already convinced of how awesome Guidance is, you can skip this section_\n",
    "\n",
    "[Guidance](https://github.com/microsoft/guidance) is a new template language from Microsoft that allows you to guide the output of lanugage models.\n",
    "This may not sound revolutionary on the surface, but if you've ever tried to compose together ouputs from a LM in a non-trivial manner and spent hours re-processing the same prompt or writing tons of boilerplate chaining code, Guidance really can be a next-level unlock.\n",
    "\n",
    "One of the biggest frustrations when it comes to chaining LM outputs is trying to \"force\" the model to generate in a specific way, for example following certain steps or in a structure that's easily programatically interpreted.\n",
    "Indeed, the classic chain-of-thought prompt (i.e. \"let's think about it step-by-step\") is merely a prompting technique to guide the model to reason about the task in a desireable way.\n",
    "But what if we could just like... make the model do what we want?\n",
    "That's where Guidance comes in.\n",
    "\n",
    "Guidance is essentially [Handlebars](https://handlebarsjs.com/) templates for language models, where a magic `gen` command invokes the model in the context of the evaluated template up to this point.\n",
    "As developers, we write the template structure of what we want the output of the model to be, and Guidance manages having the model \"fill in the blanks\".\n",
    "By way of illustration, consider:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/microsoft/guidance/main/docs/figures/json_animation.gif\" width=\"376\" height=\"234\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"https://raw.githubusercontent.com/microsoft/guidance/main/docs/figures/json_animation.gif\", width=376, height=234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the text on the white background is static, the blue background text represents variables passed in at runtime, and the green background text are the outputs generated by the language model.\n",
    "The Guidance code for this is:\n",
    "\n",
    "```\n",
    "The following is a character profile for an RPG game in JSON format.\n",
    "```json\n",
    "{\n",
    "    \"id\": \"{{id}}\",\n",
    "    \"description\": \"{{description}}\",\n",
    "    \"name\": \"{{gen 'name'}}\",\n",
    "    \"age\": {{gen 'age' pattern='[0-9]+' stop=','}},\n",
    "    \"armor\": \"{{#select 'armor'}}leather{{or}}chainmail{{or}}plate{{/select}}\",\n",
    "    \"weapon\": \"{{select 'weapon' options=valid_weapons}}\",\n",
    "    \"class\": \"{{gen 'class'}}\",\n",
    "    \"mantra\": \"{{gen 'mantra' temperature=0.7}}\",\n",
    "    \"strength\": {{gen 'strength' pattern='[0-9]+' stop=','}},\n",
    "    \"items\": [{{#geneach 'items' num_iterations=5 join=', '}}\"{{gen 'this' temperature=0.7}}\"{{/geneach}}]\n",
    "}```\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Guidance we specify how we want our final text to look, using control statements such as `gen` to specify where the model should be used to generate specific pieces.\n",
    "There are tons of different control statements -- in the above example we use the `select` statement to choose between only a few options (underneath Guidance compares the log proabilities of the options and chooses the most likely one).\n",
    "We can also specify regular expressions that define the valid form of an output (making `strength` be numeric).\n",
    "The Guidance repo has tons of [example notebooks](https://github.com/microsoft/guidance/tree/main/notebooks) that show off its various capabilities.\n",
    "One thing I will say is that, as of this writing (May 2023) there is almost no formalized documentation as Guidance is still **very** much a work-in-progess.\n",
    "I did all of my learning by looking through the example notebooks.\n",
    "\n",
    "#### Local models in Guidance\n",
    "One of the best things about Guidance is its first-class support of running on local models via [transformers](https://github.com/huggingface/transformers).\n",
    "I would go so far as to say that in Guidance local models are strictly better than using the OpenAI API (although it does support this as well).\n",
    "Perhaps its greatest feature from a quality-of-life perspective when using local models is \"acceleration\".\n",
    "\n",
    "Guidance acceleration works by caching the intermediate states of the model up to the boundary points within the template.\n",
    "When the the template is re-evaluated, Guidance can \"skip ahead\" to the point where the prompt actually changes.\n",
    "This greatly speeds up the core write-run-evaluate core developer loop when designing templates.\n",
    "If you've ever sat there re-running the same prompt for the ten thousandth time just to get to where you've made a change, then acceleration is truly a life saver.\n",
    "\n",
    "### BabyAGI\n",
    "\n",
    "[BabyAGI](https://github.com/yoheinakajima/babyagi/) is a proof-of-concept \"AGI\". In reality, it's a task management system that uses a vector database and instructs the language model to plan out and exceute tasks aimed at completing a specific objective (for example, \"paperclip the universe\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png\" width=\"496\" height=\"367\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png\", width=496, height=367)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [reference BabyAGI code](https://github.com/yoheinakajima/babyagi/blob/main/babyagi.py) uses the OpenAI APIs.\n",
    "I will refrain from editorializing here, but let's just say I'd prefer to be able to do this using open source models ðŸ™‚."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BabyAGI in Guidance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the prerequisites.\n",
    "We'll be using `transformers` and `accelerate` to run our local models and `langchain`, `faiss-cpu`, and `sentence_transformers` for embeddings and vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate langchain faiss-cpu sentence_transformers ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using [Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/) as our language model.\n",
    "Vicuna has shown to be an excellent open-source competitor to GPT-3.5.\n",
    "It is a 13B parameter model finetuned from Llama.\n",
    "\n",
    "Loading a 13B parameter model takes 52 GB of RAM when loaded at full precision or 26 GB at half precision.\n",
    "`transformers` has the helpful `load_in_8bit` parameter that reduces this to 13 GB, but unfortunately Guidance doesn't support this yet (until [PR #8](https://github.com/microsoft/guidance/pull/8) merged).\n",
    "I have a fork of Guidance that adds in support -- install this if you want to use 8-bit quantization. Otherwise, the regular `guidance` package suffices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-bit quantization support\n",
    "!pip install git+https://github.com/jquesnelle/guidance@transformers-quantization-parameters bitsandbytes\n",
    "\n",
    "# or, regular guidance\n",
    "# !pip install guidance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's time to load our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "\n",
    "llm = guidance.llms.transformers.Vicuna(\n",
    "    model=\"eachadea/vicuna-13b-1.1\",\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [LangChain](https://github.com/hwchase17/langchain) to help us with embeddings and vector databases.\n",
    "The `HuggingFaceEmbeddings` class uses [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) to generate embeddings, and we'll use the simple [FAISS vector database](https://github.com/facebookresearch/faiss) from Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain import InMemoryDocstore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_kwargs={\"device\": \"cuda:0\"})\n",
    "embedding_size = 768\n",
    "\n",
    "def make_vectorstore():\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    return FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's write some Guidance. \n",
    "BabyAGI has three core prompts: task execution, task creation, and task prioritization.\n",
    "We'll start with the task execution prompt.\n",
    "The reference implementation can be found [here](https://github.com/yoheinakajima/babyagi/blob/64e8bdb8ce5efab31b1e7e2e5a14c2ddfc6a0ee7/babyagi.py#L497)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_prompt = guidance(\"\"\"\n",
    "{{#system~}}\n",
    "{{llm.default_system_prompt}}\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "You are an AI who performs one task based on the following objective: {{objective}}.\n",
    "Take into account these previously completed tasks: {{context}}.\n",
    "Your task: {{task}}.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'result'}}\n",
    "{{~/assistant~}}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models are \"chat\" trained.\n",
    "That is to say, they've been finetuned to act as a chatbot.\n",
    "To get the best performance out of these models, you need to prompt them in the same way that they were trained.\n",
    "Unfortunately, each model has its own idiosyncrasies for this prompting.\n",
    "Normally, this would mean you would need different prompts for each model.\n",
    "However, Guidance solves this by the special `#system`, `#user`, and `#assistant` commands.\n",
    "Several popular models are supported (Vicuna, StableLM, MPT) and adding support for a new model is a simple subclass.\n",
    "Once supported, the same prompt can be used across different chat trained models.\n",
    "\n",
    "In this prompt, `objective`, `context`, and `task` are variables we'll pass in at runtime.\n",
    "We'll generate the `result` variable, which will be accessible as a property of the returned object when we call `execution_prompt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tasks(vectorstore, query, k):\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    if not results:\n",
    "        return []\n",
    "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    return [str(item.page_content) for item in sorted_results]\n",
    "\n",
    "def execute_task(vectorstore, objective, task, k=5):\n",
    "    context = get_top_tasks(vectorstore=vectorstore, query=objective, k=k) \\\n",
    "            if vectorstore is not None else []\n",
    "    return execution_prompt(objective=objective, context=context, task=task, llm=llm)[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-3babbdc8-b13d-48ad-bc95-1440f3a75482\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-3babbdc8-b13d-48ad-bc95-1440f3a75482\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{llm.default_system_prompt}}'>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are an AI who performs one task based on the following objective: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{objective}}'>Write a weather report for SF today</span>.\n",
       "Take into account these previously completed tasks: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{context}}'>[]</span>.\n",
       "Your task: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{task}}'>Write a todo list to complete the objective</span>.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;result&#x27;}}'>1. Gather current weather data for San Francisco.\n",
       "2. Analyze data to determine current weather conditions in San Francisco.\n",
       "3. Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.\n",
       "4. Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.\n",
       "5. Organize the information in a logical and easy-to-understand format.\n",
       "6. Review and edit the weather report for accuracy and clarity.\n",
       "7. Present the weather report in a professional and engaging manner.</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"3babbdc8-b13d-48ad-bc95-1440f3a75482\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1. Gather current weather data for San Francisco.\\n2. Analyze data to determine current weather conditions in San Francisco.\\n3. Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.\\n4. Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.\\n5. Organize the information in a logical and easy-to-understand format.\\n6. Review and edit the weather report for accuracy and clarity.\\n7. Present the weather report in a professional and engaging manner.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_objective = \"Write a weather report for SF today\"\n",
    "FIRST_TASK = \"Write a todo list to complete the objective\"\n",
    "sample_execute_task = execute_task(vectorstore=None, objective=sample_objective, task=FIRST_TASK)\n",
    "sample_execute_task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing in a Jupyter notebook, Guidance automatically presents the output in an easily digestable format.\n",
    "We can see the seperate `system`, `user`, and `assistant` sections and see where runtime varabiles were inserted (blue) ana the model generated new text (green).\n",
    "Every variable that is created via `gen` is available in the result object directly -- already parsed!\n",
    "\n",
    "Next up is the task creation prompt.\n",
    "A large part of the [reference implementation](https://github.com/yoheinakajima/babyagi/blob/main/babyagi.py#L420) is concerned with cleaning up the response from the model, and hoping (praying) it will follow instructions regarding how to structure the output so it can be programatically iterepreted.\n",
    "But, this is just the task the Guidance excels at!\n",
    "\n",
    "Our goal is to have the model take whatever the output of the previous task was and create a list of tasks to carry out the objective.\n",
    "This is done iteratively, so we pass in any previously incomplete tasks, and ask the model for new tasks.\n",
    "While we politely ask the model to output the tasks as an array, with Guidance we can actually _make_ it happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_prompt = guidance(\"\"\"\n",
    "{{#system~}}\n",
    "{{llm.default_system_prompt}}\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "You are a task creation AI that uses the result of an execution agent to create new tasks with the following objective: {{objective}}.\n",
    "The last completed task has the result: {{result}}.\n",
    "This result was based on this task description: {{task_description}}.\n",
    "These are the incomplete tasks: {{incomplete_tasks}}.\n",
    "Based on the result, create new tasks to be completed by the AI system that do not overlap with the incomplete tasks.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "```json\n",
    "[{{#geneach 'tasks' stop=\"]\"}}{{#unless @first}}, {{/unless}}\"{{gen 'this'}}\"{{/geneach}}]\n",
    "```\n",
    "{{~/assistant~}}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `geneach` command tells Guidance to do a looped generation, creating a list of `tasks`.\n",
    "By placing `geneach` inside of `[\"\"]` we can enforce a JSON array structure (the `unless` command is used to add neccessary commas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-0a3af691-e9f7-4a5f-b690-8a6decf54e2c\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-0a3af691-e9f7-4a5f-b690-8a6decf54e2c\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{llm.default_system_prompt}}'>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a task creation AI that uses the result of an execution agent to create new tasks with the following objective: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{objective}}'>Write a weather report for SF today</span>.\n",
       "The last completed task has the result: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{result}}'>1. Gather current weather data for San Francisco.\n",
       "2. Analyze data to determine current weather conditions in San Francisco.\n",
       "3. Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.\n",
       "4. Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.\n",
       "5. Organize the information in a logical and easy-to-understand format.\n",
       "6. Review and edit the weather report for accuracy and clarity.\n",
       "7. Present the weather report in a professional and engaging manner.</span>.\n",
       "This result was based on this task description: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{task_description}}'>Write a todo list to complete the objective</span>.\n",
       "These are the incomplete tasks: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{incomplete_tasks}}'>[]</span>.\n",
       "Based on the result, create new tasks to be completed by the AI system that do not overlap with the incomplete tasks.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>```json\n",
       "[<span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#geneach &#x27;tasks&#x27; stop=&quot;]&quot;}}{{#unless @first}}, {{/unless}}&quot;{{gen &#x27;this&#x27;}}&quot;{{/geneach}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @first}}, {{/unless}}'></span>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27;}}'>Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.</span>&quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @first}}, {{/unless}}'>, </span>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27;}}'>Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.</span>&quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @first}}, {{/unless}}'>, </span>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27;}}'>Organize the information in a logical and easy-to-understand format.</span>&quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @first}}, {{/unless}}'>, </span>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27;}}'>Review and edit the weather report for accuracy and clarity.</span>&quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @first}}, {{/unless}}'>, </span>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27;}}'>Present the weather report in a professional and engaging manner.</span>&quot;</span>]\n",
       "```</div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"0a3af691-e9f7-4a5f-b690-8a6decf54e2c\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'task_name': 'Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.'},\n",
       " {'task_name': 'Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.'},\n",
       " {'task_name': 'Organize the information in a logical and easy-to-understand format.'},\n",
       " {'task_name': 'Review and edit the weather report for accuracy and clarity.'},\n",
       " {'task_name': 'Present the weather report in a professional and engaging manner.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tasks(result, task_description, task_list, objective):\n",
    "    response = creation_prompt(\n",
    "        result=result,\n",
    "        task_description=task_description,\n",
    "        incomplete_tasks=task_list,\n",
    "        objective=objective,\n",
    "        llm=llm\n",
    "    )\n",
    "    new_tasks = [task for task in response[\"tasks\"] if task not in task_list]\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]\n",
    "\n",
    "sample_created_tasks = create_tasks(\n",
    "    result=sample_execute_task,\n",
    "    task_description=FIRST_TASK,\n",
    "    task_list=[],\n",
    "    objective=sample_objective\n",
    ")\n",
    "sample_created_tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `tasks` correctly generated and parsed!\n",
    "We then place these in a dictionary under the key `task_name` for later use in the full BabyAGI procedure.\n",
    "\n",
    "The last prompt to write is the task prioritization prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioritization_prompt = guidance(\"\"\"\n",
    "{{#system~}}\n",
    "{{llm.default_system_prompt}}\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: {{task_names}}.\n",
    "Consider the ultimate objective of your team: {{objective}}.\n",
    "Do not remove any tasks. Return the result as a numbered list, like:\n",
    "#. First task\n",
    "#. Second task\n",
    "Start the task list with number {{next_task_id}}.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{#geneach 'tasks'}}{{#if (equal @index last_task_index)}}{{break}}{{/if}}{{add @index next_task_id}}. {{gen 'this' stop=\"\\\\n\"}}\n",
    "{{/geneach}}\n",
    "{{~/assistant~}}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the task creation prompt we asked the model to output the tasks as a JSON array.\n",
    "Now we'll try a harder use case: an ordered numerical list starting with some arbitrary number.\n",
    "\n",
    "Based on experience, the model often hallucinates here and invents new tasks or repeats them.\n",
    "However, we want it to simply re-order the exisiting tasks.\n",
    "While this could be solved with a redesigned prompt or a more aligned model, we can also use the `if` command to control the number of tasks that can be outputted and stop after a predetermined number.\n",
    "\n",
    "Here, we compare the special `@index` of the current task being generated (a magic number updated by Guidance after each loop) and `break` out if it's equal to the number of tasks we know we passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-a5a1b34d-2c1b-4960-ae43-0467b29085b9\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-a5a1b34d-2c1b-4960-ae43-0467b29085b9\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{llm.default_system_prompt}}'>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{task_names}}'>[&#x27;Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.&#x27;, &#x27;Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.&#x27;, &#x27;Organize the information in a logical and easy-to-understand format.&#x27;, &#x27;Review and edit the weather report for accuracy and clarity.&#x27;, &#x27;Present the weather report in a professional and engaging manner.&#x27;]</span>.\n",
       "Consider the ultimate objective of your team: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{objective}}'>Write a weather report for SF today</span>.\n",
       "Do not remove any tasks. Return the result as a numbered list, like:\n",
       "#. First task\n",
       "#. Second task\n",
       "Start the task list with number <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{next_task_id}}'>2</span>.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#geneach &#x27;tasks&#x27;}}{{#if (equal @index last_task_index)}}{{break}}{{/if}}{{add @index next_task_id}}. {{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}\n",
       "{{/geneach}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>2</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Review and edit the weather report for accuracy and clarity.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>3</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Organize the information in a logical and easy-to-understand format.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>4</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Present the weather report in a professional and engaging manner.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>5</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{break}}'></span></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>6</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.</span>\n",
       "</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"a5a1b34d-2c1b-4960-ae43-0467b29085b9\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'task_id': 2,\n",
       "  'task_name': 'Review and edit the weather report for accuracy and clarity.'},\n",
       " {'task_id': 3,\n",
       "  'task_name': 'Organize the information in a logical and easy-to-understand format.'},\n",
       " {'task_id': 4,\n",
       "  'task_name': 'Present the weather report in a professional and engaging manner.'},\n",
       " {'task_id': 5,\n",
       "  'task_name': 'Write a clear and concise weather report for San Francisco based on the data gathered and analysis completed.'},\n",
       " {'task_id': 6,\n",
       "  'task_name': 'Include any relevant information about the forecast for the rest of the day and any potential weather-related hazards or concerns.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prioritize_tasks(this_task_id, task_list, objective):\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    response = prioritization_prompt(\n",
    "        task_names=task_names,\n",
    "        next_task_id=next_task_id,\n",
    "        objective=objective,\n",
    "        last_task_index=len(task_names) - 1,\n",
    "        llm=llm\n",
    "    )\n",
    "    return [\n",
    "        {\"task_id\": task_id, \"task_name\": task_name} \n",
    "            for task_id, task_name in \n",
    "                zip(range(next_task_id, next_task_id+len(task_list)), response[\"tasks\"])\n",
    "    ]\n",
    "\n",
    "sample_prioritized_tasks = prioritize_tasks(\n",
    "    this_task_id=1,\n",
    "    task_list=sample_created_tasks,\n",
    "    objective=sample_objective,\n",
    ")\n",
    "sample_prioritized_tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for the full BabyAGI procedure.\n",
    "It may be helpful to refer back to the diagram that shows the flow of logic, but essentially it's our three prompts being run in succession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def babyagi(objective, max_iterations=5):\n",
    "    task_list = deque([{\n",
    "        \"task_id\": 1,\n",
    "        \"task_name\": FIRST_TASK\n",
    "    }])\n",
    "    task_id_counter = 1\n",
    "    vectorstore = make_vectorstore()\n",
    "\n",
    "    while max_iterations is None or max_iterations > 0:\n",
    "        if task_list:\n",
    "\n",
    "            # Step 1: Pull the first task\n",
    "            task = task_list.popleft()\n",
    "\n",
    "            # Step 2: Execute the task\n",
    "            result = execute_task(\n",
    "                vectorstore=vectorstore,\n",
    "                objective=objective,\n",
    "                task=task[\"task_name\"]\n",
    "            )\n",
    "            this_task_id = int(task[\"task_id\"])\n",
    "\n",
    "            # Step 3: Store the result\n",
    "            result_id = f\"result_{task['task_id']}\"\n",
    "            vectorstore.add_texts(\n",
    "                texts=[result],\n",
    "                metadatas=[{\"task\": task[\"task_name\"]}],\n",
    "                ids=[result_id],\n",
    "            )\n",
    "\n",
    "            # Step 4: Create new tasks\n",
    "            new_tasks = create_tasks(\n",
    "                    result=result,\n",
    "                    task_description=task[\"task_name\"],\n",
    "                    task_list=[t[\"task_name\"] for t in task_list],\n",
    "                    objective=objective,\n",
    "                )\n",
    "            for new_task in new_tasks:\n",
    "                task_id_counter += 1\n",
    "                new_task.update({\"task_id\": task_id_counter})\n",
    "                task_list.append(new_task)\n",
    "\n",
    "            # Step 5: Reprioritize task list\n",
    "            task_list = deque(\n",
    "                prioritize_tasks(\n",
    "                    this_task_id,\n",
    "                    list(task_list),\n",
    "                    objective,\n",
    "                )\n",
    "            )\n",
    "        max_iterations = None if max_iterations is None else max_iterations - 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-490a6f44-ab86-4ac5-a85b-93e5155b7ac1\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-490a6f44-ab86-4ac5-a85b-93e5155b7ac1\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{llm.default_system_prompt}}'>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{task_names}}'>[&#x27;Make any necessary updates to the report based on new data or changes in the weather conditions&#x27;, &#x27;Ensure the report is accurate and up-to-date&#x27;, &#x27;Evaluate the effectiveness of the written report and visual graphic in conveying the weather information to the audience&#x27;, &#x27;Analyze the gathered weather data to determine the current weather conditions&#x27;, &#x27;Write a clear and concise weather report for Detroit, including temperature, precipitation, wind speed and direction, and any other relevant information&#x27;, &#x27;Determine the current weather conditions in Detroit&#x27;, &#x27;Write a clear and concise weather report for Detroit, including temperature, precipitation, wind speed and direction, and any other relevant information&#x27;, &#x27;Prioritize the tasks based on their importance and urgency to achieve the ultimate objective of writing a weather report for Detroit today.&#x27;, &#x27;Execute the tasks in the order of priority.&#x27;]</span>.\n",
       "Consider the ultimate objective of your team: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{objective}}'>Write a weather report for Detroit today</span>.\n",
       "Do not remove any tasks. Return the result as a numbered list, like:\n",
       "#. First task\n",
       "#. Second task\n",
       "Start the task list with number <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{next_task_id}}'>5</span>.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#geneach &#x27;tasks&#x27;}}{{#if (equal @index last_task_index)}}{{break}}{{/if}}{{add @index next_task_id}}. {{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}\n",
       "{{/geneach}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>5</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Prioritize the tasks based on their importance and urgency to achieve the ultimate objective of writing a weather report for Detroit today.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>6</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Execute the tasks in the order of priority.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>7</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Write a clear and concise weather report for Detroit, including temperature, precipitation, wind speed and direction, and any other relevant information.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>8</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Determine the current weather conditions in Detroit.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>9</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Evaluate the effectiveness of the written report and visual graphic in conveying the weather information to the audience.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>10</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Make any necessary updates to the report based on new data or changes in the weather conditions.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>11</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Analyze the gathered weather data to determine the current weather conditions.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>12</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Ensure the report is accurate and up-to-date.</span>\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#if (equal @index last_task_index)}}{{break}}{{/if}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{break}}'></span></span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{add @index next_task_id}}'>13</span>. <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; stop=&quot;\\n&quot;}}'>Write a clear and concise weather report for Detroit, including temperature, precipitation, wind speed and direction, and any other relevant information.</span>\n",
       "</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"490a6f44-ab86-4ac5-a85b-93e5155b7ac1\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Here is the weather report for Detroit:\\n\\nTemperature: The temperature in Detroit today is expected to reach a high of 75 degrees Fahrenheit and a low of 55 degrees Fahrenheit.\\n\\nPrecipitation: There is a chance of scattered thunderstorms throughout the day, with a 30% chance of precipitation.\\n\\nWind: The wind speed in Detroit today is expected to be light, with an average speed of 5-10 miles per hour. The wind is blowing from the southwest.\\n\\nOther relevant information: The humidity in Detroit today is expected to be around 60%, and the atmospheric pressure is 29.94 inches of mercury.\\n\\nPlease note that this weather report is based on current data and is subject to change. It is always a good idea to check the weather forecast before making any plans.\\n\\nIf you would like a visual graphic of the weather report, please let me know and I will be happy to provide one.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babyagi(\"Write a weather report for Detroit today\", max_iterations=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it, BabyAGI in Guidance using only local, open source models!\n",
    "\n",
    "Hopefully this was a helpful introduction.\n",
    "Likely this will quickly get outdated as Guidance is under very active development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
